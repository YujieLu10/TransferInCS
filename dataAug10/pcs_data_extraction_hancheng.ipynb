{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: ../data/paperconferenceid.tsv: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#------------ extract relevant conference in a file [paperid, conferenceid] -------------#\n",
    "# !cat ../data/paperconferenceid.tsv | grep '1163450153\\|1195049314\\|1166315290\\|2754292954\\|1171345118' > ../data/HCI_paperids.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ paper year -------------# data source:/data/pcsdata/selected_MAG_metadata/paperyear.tsv\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "# data_HCI = list(chain(*pd.read_csv('../data/HCI_paperids.tsv',sep=',').values.tolist()))\n",
    "data_HCI = pd.read_csv('HCI_paperids.tsv',sep='\\t')\n",
    "data_HCI.head(10)\n",
    "conf_name_map = {1163450153:'CHI', 1195049314:'CSCW', 1171345118:'UBI', 1166315290:'UIST'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_HCI.to_csv('temp.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/paperyear.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8c8c4766caf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'result_CHI'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_UBI'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_CSCW'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_UIST'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mori_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/paperyear.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mconf_name_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1163450153\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'CHI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1195049314\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'CSCW'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1171345118\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'UBI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1166315290\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'UIST'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# conf_name_map could also load by category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# data_category = pd.read_csv('../data/category.tsv',sep=',')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/paperyear.tsv'"
     ]
    }
   ],
   "source": [
    "results = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "ori_file = open('../data/paperyear.tsv')\n",
    "conf_name_map = {1163450153:'CHI', 1195049314:'CSCW', 1171345118:'UBI', 1166315290:'UIST'}\n",
    "# conf_name_map could also load by category\n",
    "# data_category = pd.read_csv('../data/category.tsv',sep=',')\n",
    "# data_category = data_category.loc[data_category['category']==\"AI\"]\n",
    "# for row in data_category.iterrows():\n",
    "#     conf_name_map[row[0]] = row[1]\n",
    "\n",
    "iter_f = iter(ori_file)\n",
    "first_line = True\n",
    "for row in iter_f:\n",
    "    if first_line:\n",
    "        first_line = False\n",
    "        continue\n",
    "    paperid_str = str(row).split()[0] # paperid\n",
    "    paperrow_str = str(row).split() # paper row\n",
    "    paperid = int(paperid_str)\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "for name, result in results.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['paperid', 'year'])\n",
    "    result_pd.to_csv('paperyear_' + str(name) + '.tsv')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ paper titles -------------# data source: /data4/pcs/papertitle.tsv\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "results_title = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "ori_pd = pd.read_csv('../data/papertitle.tsv', skiprows=1)\n",
    "pd.set_option(\"display.max_colwidth\", 100000)\n",
    "\n",
    "for row in ori_pd.iterrows():\n",
    "    paperid_str = str(row[1]).split('\\\\t')[1].split()[1] # paperid\n",
    "    paper_title = str(row[1]).split('\\\\t')[2].split('\\n')[0]\n",
    "    paperrow_str = [paperid_str, paper_title]\n",
    "    paperid = int(paperid_str)\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "        \n",
    "for name, result in results_title.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['paperid', 'title'])\n",
    "    result_pd.to_csv('papertitle_' + str(name) + '.tsv')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ paper author order -------------#\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "results_author = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "ori_paperauthor = pd.read_csv('../data/paperauthororder.tsv',skiprows=1)\n",
    "for row in ori_paperauthor.iterrows():\n",
    "    paperid_str = str(row[1]).split('    ')[1].split('\\\\t')[0] # paperid\n",
    "    paperrow_str = str(row[1]).split('    ')[1].split('\\n')[0].split('\\\\t') # paper row\n",
    "    paperid = int(paperid_str)\n",
    "\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results_author['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "\n",
    "for name, result in results_author.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['paperid', 'authorid', 'authororder'])\n",
    "    result_pd.to_csv('paperauthororder_' + str(name) + '.tsv')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## faster implementation for detecting author affiliation at paper level\n",
    "f = open('paperauthoridaffiliationname.tsv')\n",
    "paper_author_affiliation = {}\n",
    "paper_author_id = {}\n",
    "line = f.readline()\n",
    "while line:\n",
    "    paperid = line.split('\\t')[0]\n",
    "    authorid = line.split('\\t')[1]\n",
    "    affiliation = line.split('\\t')[2][:-1]\n",
    "    if paperid not in paper_author_affiliation:\n",
    "        paper_author_id[paperid] = [authorid]\n",
    "        paper_author_affiliation[paperid] = [affiliation]\n",
    "    else:\n",
    "        paper_author_id[paperid].append(authorid)\n",
    "        paper_author_affiliation[paperid].append(affiliation)\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get author affiliation, id level information related to hci conferences\n",
    "Paperid = []\n",
    "Affiliation = []\n",
    "AuthorId = []\n",
    "for paperid in data_HCI['paperid']:\n",
    "    paperid = str(paperid)\n",
    "    try:\n",
    "        \n",
    "        Affiliation.append(paper_author_affiliation[paperid])\n",
    "        AuthorId.append(paper_author_id[paperid])\n",
    "        Paperid.append(paperid)\n",
    "    except:\n",
    "        pass\n",
    "df = pd.DataFrame({'paperid':Paperid, 'authorid':AuthorId,'Affiliation':Affiliation})\n",
    "df.to_csv('HCI_paper_authorid_affiliation.tsv',sep='\\t', index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data complete!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conf_name_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-89d5196359ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpaperid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_HCI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paperid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mresults_affiliation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_name_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_HCI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_HCI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paperid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mpaperid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'confid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaperrow_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_affiliation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conf_name_map' is not defined"
     ]
    }
   ],
   "source": [
    "#------------ paper affiliations -------------#\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "results_affiliation = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "#ori_pd = pd.read_csv('../data/paperauthoridaffiliationname.tsv', sep='\\t', skiprows=1)\n",
    "ori_pd = pd.read_csv('/dfs/scratch0/hanchcao/Transfer_CS/transfer_cs/108362-V14/selected-MAG-metadata-2018/paperauthoridaffiliationname.tsv', sep='\\t', skiprows=1)\n",
    "print ('load data complete!')\n",
    "pd.set_option(\"display.max_colwidth\", 100000)\n",
    "\n",
    "count = 0\n",
    "for row in ori_pd.iterrows():\n",
    "    count += 1\n",
    "    if count%10000 ==0 :\n",
    "        print (count)\n",
    "    paperid_str = str(row[1]).split('\\n')[0].split()[1]\n",
    "    authorid = str(row[1]).split('\\n')[1].split()[1]\n",
    "    affiliationname = str(row[1]).split('\\n')[2].split()[1]\n",
    "    paperrow_str = [paperid_str, authorid, affiliationname]\n",
    "    paperid = int(paperid_str)\n",
    "\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results_affiliation['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "\n",
    "for name, result in results_affiliation.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['paperid', 'authorid', 'affiliationname'])\n",
    "    result_pd.to_csv('authoraffname_' + str(name) + '.tsv', encoding='utf-8')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c56a15e18b33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpaperid_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mauthorid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0maffiliationname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpaperrow_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpaperid_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthorid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffiliationname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpaperid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaperid_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__unicode__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__bytes__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__unicode__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         self.to_string(buf=buf, name=self.name, dtype=self.dtype,\n\u001b[0;32m-> 1235\u001b[0;31m                        max_rows=max_rows, length=show_dimensions)\n\u001b[0m\u001b[1;32m   1236\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows)\u001b[0m\n\u001b[1;32m   1277\u001b[0m                                         \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m                                         max_rows=max_rows)\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;31m# catch contract violations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'Series([], '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfooter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mfmt_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhave_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mfmt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_formatted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36m_get_formatted_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mhave_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mfmt_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfmt_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhave_header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, name, formatter, **kwargs)\u001b[0m\n\u001b[1;32m   2378\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2380\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_with_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_with_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_format_with_header\u001b[0;34m(self, header, na_rep, **kwargs)\u001b[0m\n\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0;31m# could have nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2398\u001b[0;31m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2400\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36misna\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mName\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    118\u001b[0m     elif isinstance(obj, (ABCSeries, np.ndarray, ABCIndexClass,\n\u001b[1;32m    119\u001b[0m                           ABCExtensionArray)):\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;31m# object array of non-strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnaobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in ori_pd.iterrows():\n",
    "    count += 1\n",
    "    if count%10000 ==0 :\n",
    "        print (count)\n",
    "    paperid_str = str(row[1]).split('\\n')[0].split()[1]\n",
    "    authorid = str(row[1]).split('\\n')[1].split()[1]\n",
    "    affiliationname = str(row[1]).split('\\n')[2].split()[1]\n",
    "    paperrow_str = [paperid_str, authorid, affiliationname]\n",
    "    paperid = int(paperid_str)\n",
    "\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results_affiliation['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "\n",
    "for name, result in results_affiliation.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['paperid', 'authorid', 'affiliationname'])\n",
    "    result_pd.to_csv('authoraffname_' + str(name) + '.tsv')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ paper citations -------------# data source: /data4/pcs/papercitations\n",
    "import os\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "results_citing = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "results_cited = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "\n",
    "# all citation raw file are listed in papercitations directory\n",
    "files = os.listdir(\"../data/papercitations\")\n",
    "for file in files:\n",
    "    firstline = True\n",
    "    paper_citation_file = open(os.path.join(\"../data/papercitations\", file))\n",
    "    iter_f = iter(paper_citation_file)\n",
    "    for row in iter_f:\n",
    "        if firstline:\n",
    "            firstline = False\n",
    "            continue\n",
    "        if len(str(row).split()) < 2:\n",
    "            continue\n",
    "        citing_paperid_str = str(row).split()[0] # citingpaperid\n",
    "        cited_paperid_str = str(row).split()[1]\n",
    "        paperrow_str = [citing_paperid_str, cited_paperid_str]\n",
    "        paperid = int(citing_paperid_str)\n",
    "        paperid2 = int(cited_paperid_str)\n",
    "\n",
    "        if paperid in data_HCI['paperid'].values:\n",
    "            results_citing['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "\n",
    "        if paperid2 in data_HCI['paperid'].values:\n",
    "            results_cited['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid2]['confid'].values)])].append(list(paperrow_str))\n",
    "\n",
    "for name, result in results_citing.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['citingpaperid', 'citedpaperid'])\n",
    "    result_pd.to_csv('paperciting_' + str(name) + '.tsv')\n",
    "\n",
    "for name, result in results_cited.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['citingpaperid', 'citedpaperid'])\n",
    "    result_pd.to_csv('papercited_' + str(name) + '.tsv')\n",
    "\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ paper citations science -------------# data source: /data/pcsdata/pcs.tsv\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "\n",
    "results_pcs = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "ori_file = open('../data/pcs.tsv')\n",
    "iter_f = iter(ori_file)\n",
    "first_line = True\n",
    "for row in iter_f:\n",
    "    if first_line:\n",
    "        first_line = False\n",
    "        continue\n",
    "    paperrow_str = str(row).split() # paper row\n",
    "    paperid_str = paperrow_str[2]\n",
    "    paperid = int(paperid_str)\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results_pcs['result_{}'.format(conf_name_map[int(data_HCI.loc[data_HCI['paperid']==paperid]['confid'].values)])].append(list(paperrow_str))\n",
    "\n",
    "for name, result in results_pcs.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['reftype', 'confscore', 'paperid', 'patent'])\n",
    "    result_pd.to_csv('papercitationscience_' + str(name) + '.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,reftype,confscore,paperid,patent</th>\n",
       "      <th>paperid</th>\n",
       "      <th>confid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,app,9,2134161165,10001804</td>\n",
       "      <td>2243662716</td>\n",
       "      <td>1163450153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,app,9,1967451823,10001885</td>\n",
       "      <td>2244265604</td>\n",
       "      <td>1163450153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2,app,9,1967451823,10001888</td>\n",
       "      <td>2244428935</td>\n",
       "      <td>1163450153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3,app,10,2005198142,10001888</td>\n",
       "      <td>2244483578</td>\n",
       "      <td>1163450153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4,app,10,2152754623,10001897</td>\n",
       "      <td>2244508988</td>\n",
       "      <td>1163450153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ,reftype,confscore,paperid,patent     paperid      confid\n",
       "0       0,app,9,2134161165,10001804  2243662716  1163450153\n",
       "1       1,app,9,1967451823,10001885  2244265604  1163450153\n",
       "2       2,app,9,1967451823,10001888  2244428935  1163450153\n",
       "3      3,app,10,2005198142,10001888  2244483578  1163450153\n",
       "4      4,app,10,2152754623,10001897  2244508988  1163450153"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------ patent inventors -------------# data source:pcs/patent_dblpdata/patent_inventor.tsv\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "patent_data_HCI = pd.read_csv('../data/papercitationscience_result.tsv',sep='\\t')\n",
    "patent_data_HCI = patent_data_HCI.merge(data_HCI, left_index=True, right_index=True)\n",
    "patent_data_HCI.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_inventors = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "\n",
    "ori_patentinventors = pd.read_csv('../data/patent_inventor.tsv',skiprows=1)\n",
    "for row in ori_patentinventors.iterrows():\n",
    "    patent_id = str(row[1]).split('    ')[1].split('\\\\t')[0]\n",
    "    patentinventors_row = str(row[1]).replace(\"\\\"\",\"\").split('    ')[1].split('\\n')[0].split('\\\\t')\n",
    "\n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results_inventors['result_{}'.format(conf_name_map[int(patent_data_HCI.loc[patent_data_HCI['paperid']==paperid]['confid'].values)])].append(list(patentinventors_row))\n",
    "        \n",
    "for name, result in results_inventors.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['patent_id', 'inventor_id', 'location_id'])\n",
    "    result_pd.to_csv('patentinventors_' + str(name) + '.tsv')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ patent abstract -------------# data source: /data4/pcs/abstract/brf_sum_text.tsv\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "results_abstract = {'result_CHI':[], 'result_UBI':[], 'result_CSCW':[], 'result_UIST':[]}\n",
    "\n",
    "ori_patent_abstract = pd.read_csv('../data/brf_sum_text.tsv', sep='\\t', skiprows=1)\n",
    "pd.set_option(\"display.max_colwidth\", 100000)\n",
    "for row in ori_patent_abstract.iterrows():\n",
    "    uuid = str(row[1]).split('\\n')[0].split()[1].strip(\"\\n\")\n",
    "    patent_id = str(row[1]).split('\\n')[1].split()[1].strip(\"\\n\")\n",
    "    abstract = str(row[1]).split('\\n')[2].split('         ')[1]\n",
    "    patent_abstract_row = [uuid, patent_id, abstract]\n",
    "    \n",
    "    if paperid in data_HCI['paperid'].values:\n",
    "        results_abstract['result_{}'.format(conf_name_map[int(patent_data_HCI.loc[patent_data_HCI['paperid']==paperid]['confid'].values)])].append(list(patent_abstract_row))\n",
    "\n",
    "for name, result in results_inventors.items():\n",
    "    result_pd = pd.DataFrame(data=result, columns=['uuid', 'patent_id', 'abstract'])\n",
    "    result_pd.to_csv('patent_abstract_' + str(name) + '.tsv')\n",
    "print(\">>> done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ patent year -------------# data source:/patentsview/patent.tsv\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "HCI_ori_pd = None\n",
    "for path,directory,files in os.walk('../data/patentinventors/'):\n",
    "    # here, we have conf_id name of CHI, CSCW, UBI, UIST\n",
    "    for file in files:\n",
    "        ori_pd = pd.read_csv(os.path.join(path, file))\n",
    "        conf_id = file[file.index('_') + 1:-4]\n",
    "        # add conf_id property to patent data\n",
    "        ori_pd['conf_id'] = conf_id\n",
    "        if HCI_ori_pd is None:\n",
    "            HCI_ori_pd = ori_pd\n",
    "        else:\n",
    "            HCI_ori_pd = pd.concat([HCI_ori_pd, ori_pd],axis=0)\n",
    "# extract patent year data\n",
    "print(\"start load\")\n",
    "patent_pd = pd.read_csv('patent.tsv',sep='\\t')\n",
    "# merge ori_conf_pd_map\n",
    "print(\"start merge\")\n",
    "HCI_ori_pd = HCI_ori_pd.merge(patent_pd, left_on='patent_id', right_on='id')\n",
    "HCI_ori_pd.to_csv('patent_year_inventor.tsv')\n",
    "HCI_ori_pd.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('mixer': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b067056e18d69d2380e6dc5b62d17b439a214bcf514f32d0e4e8dd6f4adc633c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
